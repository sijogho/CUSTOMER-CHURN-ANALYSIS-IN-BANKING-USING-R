install.packages("corrplot")
install.packages("caret")
install.packages("pheatmap")
install.packages("PRROC")
install.packages("pdp")
install.packages("DataExplorer")
install.packages("reshape2")
library(tidyverse)
library(ggplot2)
library(plotly)
library(lattice)
library(ggExtra)
library(corrplot)
library(heatmaply)
library(PerformanceAnalytics)
library(GGally)
library(dplyr)
library(e1071)
library(pROC)
library(corrplot)
library(caret)
library(pheatmap)
library(PRROC)
library(pdp)
library(DataExplorer)
library(reshape2)
data <- read.csv("Customer-Churn-Records.csv", stringsAsFactors =TRUE, header = TRUE)
# install all packages
install.packages("tidyverse")
install.packages("tidyverse")
install.packages("ggplot2")
install.packages("plotly")
install.packages("lattice")
install.packages("ggExtra")
install.packages("corrplot")
install.packages("heatmaply")
install.packages("PerformanceAnalytics")
install.packages("GGally")
install.packages("dplyr")
install.packages("e1071")
install.packages("pROC")
install.packages("corrplot")
install.packages("caret")
install.packages("pheatmap")
install.packages("PRROC")
install.packages("pdp")
install.packages("DataExplorer")
install.packages("reshape2")
#Calling Libraries
library(tidyverse)
library(ggplot2)
library(plotly)
library(lattice)
library(ggExtra)
library(corrplot)
library(heatmaply)
library(PerformanceAnalytics)
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
install.packages("dplyr")
library(dplyr)
library(e1071)
library(pROC)
library(corrplot)
library(caret)
library(pheatmap)
library(PRROC)
library(pdp)
library(DataExplorer)
library(reshape2)
# Loading in Data_set
library(readr)
data <- read.csv("Customer-Churn-Records.csv", stringsAsFactors =TRUE, header = TRUE)
data <- read.csv("Customer-Churn-Records.csv", stringsAsFactors =TRUE, header = TRUE)
install.packages("tidyverse")
install.packages("corrplot")
install.packages("gridExtra")
install.packages("GGally")
install.packages("knitr")
install.packages("caret")
install.packages("GGally")
install.packages("mlbench")
install.packages("e1071")
install.packages("kernlab")
install.packages("DataExplorer")
install.packages("plotly")
#load the required libraries
library(mlbench)
library(caret)
install.packages("ggplot2")
library(caret)
library(tidyverse)
library(tidyverse)
install.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
setwd("C:/Users/pc/OneDrive - Teesside University/R (ICA)")
#Calling Libraries
library(tidyverse)
library(ggplot2)
library(plotly)
library(lattice)
library(ggExtra)
library(corrplot)
library(heatmaply)
library(PerformanceAnalytics)
library(GGally)
library(dplyr)
library(e1071)
library(pROC)
library(corrplot)
library(caret)
library(pheatmap)
library(PRROC)
library(DataExplorer)
library(gridExtra)
library(DMwR)
library(class)
# Loading in Data_set
library(readr)
data <- read.csv("Customer-Churn-Records.csv", stringsAsFactors =TRUE, header = TRUE)
#Checking the structure and summary of the dataset
str(data)
summary(data)
# Check for missing data
anyNA(data)
# check for duplicate row
duplicated_rows <- data[duplicated(data), ]
# Print or view the duplicated rows
print(duplicated_rows)
#Removing unnecessary columns
data <-select(data,-RowNumber,-CustomerId,-Surname)
# converting Exited into factor
data$Exited <- as.factor(data$Exited)
# Boxplot for the distribution of Age
ggplot(data, aes(x = Age, y = Exited)) +
geom_boxplot(fill = "blue" ) +
labs(title = "Boxplot of Age Distribution", y = "Exited") +
theme_minimal()
# converting Exited into factor
data$Exited <- as.factor(data$Exited)
# Boxplot for the distribution of Age
ggplot(data, aes(x = Age, y = Exited)) +
geom_boxplot(fill = "blue" ) +
labs(title = "Boxplot of Age Distribution", y = "Exited") +
theme_minimal()
# Histogram of age by churn status
ggplot(data, aes(x = Age, fill = factor(Exited))) +
geom_histogram(binwidth = 5, position = "identity", alpha = 0.8) +
labs(title = "Histogram of Age by Churn Status", x = "Age", y = "Count") +
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status") +
theme_minimal()
# Boxplot for Distribution of churn by Credit Score
ggplot(data, aes(x = factor(Exited), y = CreditScore, fill = factor(Exited))) +
geom_boxplot() +
labs(title = "Churn Distribution by Credit Score", x = "Churn Status", y = "Credit Score") +
scale_x_discrete(labels = c("Loyal", "Churned")) +
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status")
theme_minimal()
# Histogram of churn by Credit Score
ggplot(data, aes(x = CreditScore, fill = factor(Exited))) +
geom_histogram(binwidth = 10, position = "identity", alpha = 0.8) +
labs(title = "Histogram of Churn by Credit Score", x = "Credit Score", y = "Count") +
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status") +
theme_minimal()
# Boxplot of balance by churn status
ggplot(data, aes(x = factor(Exited), y = Balance, fill = factor(Exited))) +
geom_boxplot() +
labs(title = "Boxplot of Balance Distribution by Churn Status", x = "Churn Status", y = "Balance") +
scale_x_discrete(labels = c("Loyal", "Churned")) +  # Customize x-axis labels
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status") +
theme_minimal()
# Histogram of churn by Credit Score
ggplot(data, aes(x = CreditScore, fill = factor(Exited))) +
geom_histogram(binwidth = 10, position = "identity", alpha = 0.8) +
labs(title = "Histogram of Churn by Credit Score", x = "Credit Score", y = "Count") +
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status") +
theme_minimal()
# Boxplot of balance by churn status
ggplot(data, aes(x = factor(Exited), y = Balance, fill = factor(Exited))) +
geom_boxplot() +
labs(title = "Boxplot of Balance Distribution by Churn Status", x = "Churn Status", y = "Balance") +
scale_x_discrete(labels = c("Loyal", "Churned")) +  # Customize x-axis labels
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status") +
theme_minimal()
#Calling Libraries
library(tidyverse)
library(ggplot2)
library(plotly)
library(lattice)
library(ggExtra)
library(corrplot)
library(heatmaply)
library(PerformanceAnalytics)
library(GGally)
library(dplyr)
library(e1071)
library(pROC)
library(corrplot)
library(caret)
library(pheatmap)
library(PRROC)
library(DataExplorer)
library(gridExtra)
library(DMwR)
library(class)
# Loading in Data_set
library(readr)
#Calling Libraries
library(tidyverse)
library(ggplot2)
library(plotly)
library(lattice)
library(ggExtra)
library(corrplot)
library(heatmaply)
library(PerformanceAnalytics)
library(GGally)
library(dplyr)
library(e1071)
library(pROC)
library(corrplot)
library(caret)
library(pheatmap)
library(PRROC)
library(DataExplorer)
library(gridExtra)
library(DMwR)
library(class)
# Loading in Data_set
library(readr)
data <- read.csv("Customer-Churn-Records.csv", stringsAsFactors =TRUE, header = TRUE)
#Checking the structure and summary of the dataset
str(data)
summary(data)
# Check for missing data
anyNA(data)
# check for duplicate row
duplicated_rows <- data[duplicated(data), ]
# Print or view the duplicated rows
print(duplicated_rows)
#Removing unnecessary columns
data <-select(data,-RowNumber,-CustomerId,-Surname)
# converting Exited into factor
data$Exited <- as.factor(data$Exited)
# Boxplot for the distribution of Age
ggplot(data, aes(x = Age, y = Exited)) +
geom_boxplot(fill = "blue" ) +
labs(title = "Boxplot of Age Distribution", y = "Exited") +
theme_minimal()
# Histogram of age by churn status
ggplot(data, aes(x = Age, fill = factor(Exited))) +
geom_histogram(binwidth = 5, position = "identity", alpha = 0.8) +
labs(title = "Histogram of Age by Churn Status", x = "Age", y = "Count") +
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status") +
theme_minimal()
# Boxplot for Distribution of churn by Credit Score
ggplot(data, aes(x = factor(Exited), y = CreditScore, fill = factor(Exited))) +
geom_boxplot() +
labs(title = "Churn Distribution by Credit Score", x = "Churn Status", y = "Credit Score") +
scale_x_discrete(labels = c("Loyal", "Churned")) +
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status")
theme_minimal()
# Histogram of churn by Credit Score
ggplot(data, aes(x = CreditScore, fill = factor(Exited))) +
geom_histogram(binwidth = 10, position = "identity", alpha = 0.8) +
labs(title = "Histogram of Churn by Credit Score", x = "Credit Score", y = "Count") +
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status") +
theme_minimal()
# Boxplot of balance by churn status
ggplot(data, aes(x = factor(Exited), y = Balance, fill = factor(Exited))) +
geom_boxplot() +
labs(title = "Boxplot of Balance Distribution by Churn Status", x = "Churn Status", y = "Balance") +
scale_x_discrete(labels = c("Loyal", "Churned")) +  # Customize x-axis labels
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status") +
theme_minimal()
# Histogram of balance by churn status
ggplot(data, aes(x = Balance, fill = factor(Exited))) +
geom_histogram(binwidth = 5000, color = "white", alpha = 0.8, position = "identity") +
labs(title = "Histogram of Balance by Churn Status", x = "Balance", y = "Count") +
scale_fill_manual(values = c("0" = "blue", "1" = "red"), name = "Churn Status") +
theme_minimal()
# Distribution of Bank Customers by Churn Status
ggplot(data, aes(x = factor(Exited), fill = factor(Exited))) +
geom_bar() +
labs(title = "Distribution of Bank Customers by Churn Status", x = "Churn Status", y = "Number of Customers") +
scale_fill_manual(values = c("0"="blue", "1"="red"), name = "Exited")+
scale_x_discrete(labels = c("0", "1")) +
theme_minimal()
# Bar chart for 'Geographical location' vs 'Exited'
ggplot(data, aes(x = factor(Geography), fill = factor(Exited))) +
geom_bar(position = "dodge", alpha = 0.8) +
labs(title = "Exited Rate by Geographical location",
x = "Geography",
y = "Percentage") +
scale_y_continuous(labels = scales::percent_format(scale = 100)) +
scale_fill_manual(values = c("0"="blue", "1"="red"), name = "Exited") +
theme_minimal()
# Bar chart for 'Gender' vs 'Exited'
ggplot(data, aes(x = factor(Gender), fill = factor(Exited))) +
geom_bar(position = "dodge", alpha = 0.8) +
scale_fill_manual(values = c("0"="blue", "1"="red"), name = "Exited")
labs(title = "Exited Rate by Gender",
x = "Gender",
y = "Percentage") +
scale_y_continuous(labels = scales::percent_format(scale = 100)) +
theme_minimal()
# Bar chart for 'Card.Type' vs 'Exited'
ggplot(data, aes(x = factor(Card.Type), fill = factor(Exited))) +
geom_bar(position = "dodge", alpha = 0.8) +
labs(title = "Exited Rate by Card Type",
x = "Card Type",
y = "Percentage") +
scale_y_continuous(labels = scales::percent_format(scale = 100)) +
scale_fill_manual(values = c("0"="blue", "1"="red"), name = "Exited")
theme_minimal()
# Defining customer salary ranges
salary_ranges <- c(0, 50000, 100000, 150000, max(data$EstimatedSalary))
# Create a new variable 'Salary_Group' based on custom salary ranges
data$Salary_Group <- cut(data$EstimatedSalary, breaks = salary_ranges, labels = c("0-50K", "50K-100K", "100K-150K", "150K+"))
# Bar chart for 'Salary_Group' vs 'Exited'
ggplot(data, aes(x = Salary_Group, fill = factor(Exited))) +
geom_bar(position = "dodge", alpha = 0.8) +
labs(title = "Exited Rate by Estimated Salary Group",
x = "Estimated Salary Group",
y = "Percentage") +
scale_y_continuous(labels = scales::percent_format(scale = 100)) +
scale_fill_manual(values = c("0"="blue", "1"="red"), name = "Exited")
theme_minimal()
#REMOVING UNNECESSARY VARIABLES AFTER VISUALISATION
data <- select(data,- Salary_Group)
# converting Geography, Gender and Cardtype to numeric
data <- data %>%
mutate(
Geography = as.numeric(Geography),
Gender = as.numeric(Gender),
Card.Type = as.numeric(Card.Type)
)
str(data)
#Correlation Analysis
# converting Exited to Numeric
data$Exited <- as.numeric(data$Exited)
# Calculate the correlation matrix
dat <- select(data,-Exited)
correlation_matrix <- cor(dat)
# Create a correlation matrix heatmap
corrplot(correlation_matrix, method = "color", tl.col = "black", tl.srt = 45)
print(correlation_matrix)
# find highly correlated features
highly_correlated <- findCorrelation(correlation_matrix,
cutoff=.6,
verbose = TRUE,
names = TRUE)
highly_correlated <- data.frame(highly_correlated)
highly_correlated
#NORMALISATION
# Convert 'Exited' to a factor variable
data$Exited <- as.factor(data$Exited)
# Normalize all variables except the target variable
data_norm <- data %>%
# Select columns to normalize (excluding 'Exited')
select(1:14) %>%
# Convert non-numeric values to numeric
mutate(across(everything(), ~as.numeric(as.character(.)))) %>%
# Center and scale the selected variables (normalizing)
mutate(across(everything(), scale)) %>%
# Bind the normalized variables to the original dataset (excluding 'Exited')
bind_cols(data %>% select(Exited)) %>%
# Ensure all columns are numeric
mutate(across(everything(), as.numeric))
# Convert 'Exited' to a factor variable
data_norm$Exited <- as.factor(data_norm$Exited)
#Data preprocesing
# check missing values ans replace if found
anyNA(data_norm)
#Data Up-sampling
# From my data frame
#SMOTE BALANCING TECHNIQUE
data_norm$Exited <- as.factor(data_norm$Exited)
#BALANCING THE TARGET VARIABLE USING SMOTE
data2<- SMOTE(Exited ~ ., data = data_norm, perc.over = 100, perc.under = 200, k = 5)
# Check class distribution after SMOTE
table(data2$Exited)
#PLOTTING DATA BEFORE & AFTER SMOTE BALANCING
# original data
p1 <- ggplot(data, mapping = aes(x = Exited)) +
geom_bar(colour = "red") +
labs(title = "Original data") +
theme_bw()
# upsampled data
p2 <- ggplot(data2, mapping = aes(x = Exited)) +
geom_bar(colour = "blue") +
labs(title = "Upsampled data") +
theme_bw()
# subplot
grid.arrange(p1, p2, ncol = 2)
# Convert the target variable to a factor
data2$Exited<- as.factor(data2$Exited)
#DATA SPLICING(Dividing upsampled data into train & test)
#SET SEED FOR REPRODUCTIVITY
set.seed(123)
#SETTING SAMPLE FOR SPILITTING AS 70%
dat.d <- sample(1:nrow(data2),size=nrow(data2)*0.7,replace = FALSE)
#CREATING TRAINING DATASET
train <- data2[dat.d,]
#CREATING TESTING DATASET
test <- data2[-dat.d,]
#CREATING A SEPERATE DATAFRAME FOR Exited(TARGET VARIABLE)
train.data <- data2[dat.d,"Exited"]
test.data <- data2[-dat.d,"Exited"]
#CHEKING FOR NUMBER OFOBSERVATIONS IN EACH DATAFRAME
NROW(train.data)
NROW(test.data)
#SET SEED TO ENSURE PRODUCIBILITY OF RANDOM NUMBERS
set.seed(123)
train_indices <- sample(1:nrow(data2), 0.7 * nrow(data2))
# Train the SVM model
svm_linear <- svm(Exited ~ ., data = train, kernel = "linear", cost = 10)
# Make predictions on the testing set
test_pred <- predict(svm_linear, newdata = test)
# Evaluating the SVM linear model
confusion_matrix <- table(test_pred, test$Exited)
print(confusion_matrix)
# Calculating accuracy of the model
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
cat("Accuracy:", accuracy, "\n")
#USING CONFUSION MATRIX TO CALCULATE THE ACCURACY
confusionMatrix(table(test_pred ,test.data))
# create grid
grid <-expand.grid(C=c(0, 0.01, 0.05, 0.1, 0.25, 0.5,0.75, 1, 1.25, 1.5, 1.75, 2.5))
# retraining the model with grid to know the best value for c
svm_Linear_Grid <- train(Exited~.,data = train,
method = "svmLinear",
preProcess =c("center", "scale"), tuneGrid = grid,
tuneLength = 10)
svm_Linear_Grid
#plot the SVM
plot(svm_Linear_Grid)
# Testing the grid
test_pred_Grid <-predict(svm_Linear_Grid, newdata = test)
test_pred_Grid
confusionMatrix(table(test_pred_Grid,test$Exited))
# K-NEAREST NEIGHBOUR
#SET SEED TO ENSURE RPRODUCIBILITY OF RANDOM NUMBERS
set.seed(123)
#train countrol
ch_results <- train(
Exited ~ .,
data = data2,
method = "knn",
trControl = trainControl(method = "cv", number = 10)
)
anyNA(data2)
#There are have 5706 observations in the training data.The square root of 5706 is 75.53, therefore I would be creating
#2 models. One with K Value as 75 and the other with K Value as 76
knn.75 <- knn(train=train, test=test, cl=train.data, k=75)
knn.76 <- knn(train=train, test=test, cl=train.data, k=76)
#MODEL EVALUATION (ACCURACY)
ACC.75 <- 100 * sum(test.data == knn.75)/NROW(test.data)
ACC.76 <- 100 * sum(test.data == knn.76)/NROW(test.data)
#VIEW ACCURACY
ACC.75
ACC.76
#CHECKING PREDICTION AGAINST ACTUAL VALUE IN TABULAR FORM FOR BOTH K VALUES
table(knn.75 ,test.data)
knn.75
table(knn.76 ,test.data)
knn.76
#USING CONFUSION MATRIX TO CALCULATE THE ACCURACY FOR BOTH K VALUES
confusionMatrix(table(knn.75 ,test.data))
confusionMatrix(table(knn.76 ,test.data))
#OPTIMIZATION
#INITIALIZING A VARIABLE i TO 1
i = 1
#CREATING A NUMERIC VECTOR OF LENTH 48 TO STORE ACCURACY VALUES FOR EACH K VALUE
k.optm = numeric(76)
#CREATING A LOOP OF VALUE i FROM 1 TO 48
for (i in 1:76) {
# FITTING A KNN MODEL WITH CURRENT VALUE OF K(i)
knn.mod <- knn(train = train, test = test, cl = train.data, k = i)
#Calculating percentage accuracy of current k and storing in k.optm
k.optm[i] <- 100 * sum(test.data == knn.mod) / length(test.data)
#PRINTING THE ITIERATUION NUMBER,  EQUAL SIGN AND ACCURACY FOR CURRENT K
cat(i, '=', k.optm[i], "\n")
}
#PLOTTING KNN MODEL FOR DIFFERENT VALUES OF K IN K.optm
plot(k.optm, type="b", xlab="K- Value",ylab="Accuracy level")
#SHOWING THE KNN MODEL WITH THE HIGHEST ACCURACY
knn.1 <- knn(train=train, test=test, cl=train.data, k= 1)
#CALCULATING THE PERCENTAGE ACCURACY OF THE MODEL
ACC.1 <- 100 * sum(test.data == knn.1)/NROW(test.data)
#CHECKING PREDICTION AGAINST ACTUAL VALUE IN TABULAR FORM
table(knn.1 ,test.data)
knn.1
#USING CONFUSION MATRIX TO CALCULATE THE ACCURACY
confusionMatrix(table(knn.1 ,test.data))
# Comparing SVM to KNN
#train the KNN model
set.seed(123)
fit.knn <- train(Exited~., data=train,
method="knn", preProcess = c("center", "scale"),
trControl=trainControl())
#train the SVM model
set.seed(123)
fit.svm <-train(Exited~., data=train,
method="svmLinear",preProcess =c("center", "scale"),
trControl=trainControl())
# Compare the algorithms
comp <- resamples(list(SVM=fit.svm, KNN=fit.knn))
summary(comp)
dotplot(comp)
